{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Welcome to Lab: GPA 🎓\n",
    "\n",
    "In this lab, you'll explore the GPA dataset again to find out more about the courses at Illinois!\n",
    "\n",
    "Fun fact: the dataset you're using in this lab is the same dataset that Professor Wade uses to make the GPA visualizations! :)  Check this out here if you haven't seen it already: [https://waf.cs.illinois.edu/discovery/grade_disparity_between_sections_at_uiuc/](https://waf.cs.illinois.edu/discovery/grade_disparity_between_sections_at_uiuc/)\n",
    "\n",
    "\n",
    "A few tips to remember:\n",
    "\n",
    "- **You are not alone on your journey in learning programming!**  You have your lab TA, your CAs, your lab group, and the professors (Prof. Wade and Prof. Karle), who are all here to help you out!\n",
    "- If you find yourself stuck for more than a few minutes, ask a neighbor or course staff for help!  When you are giving help to your neighbor, explain the **idea and approach** to the problem without sharing the answer itself so they can have the same **<i>ah-hah</i>** moment!\n",
    "- We are here to help you!  Don't feel embarrassed or shy to ask us for help!\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meet your CAs and TA if you haven't already!\n",
    "# ...first name is enough, we'll know who they are! :)\n",
    "ta_name = \"\"\n",
    "ca1_name = \"\"\n",
    "ca2_name = \"\"\n",
    "ca3_name = \"\"\n",
    "\n",
    "\n",
    "# Say hello to each other!\n",
    "# - Groups of 3 are ideal :)\n",
    "# - However, groups of 2 or 4 are fine too!\n",
    "#\n",
    "# Question of the Day (QOTD) to Ask Your Group: \"What's your favorite social media?\"\n",
    "partner1_name = \"\"\n",
    "partner1_netid = \"\"\n",
    "partner1_favsocialmedia = \"\"\n",
    "\n",
    "partner2_name = \"\"\n",
    "partner2_netid = \"\"\n",
    "partner2_favsocialmedia = \"\"\n",
    "\n",
    "partner3_name = \"\"\n",
    "partner3_netid = \"\"\n",
    "partner3_favsocialmedia= \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1: Exploring GPA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the GPA Dataset\n",
    "\n",
    "Before we begin exploring the GPA Dataset, we've got to load it in! The most recent version of the \"GPA Dataset\" (up to Spring 2023) is available here:\n",
    "```\n",
    "https://waf.cs.illinois.edu/discovery/gpa.csv\n",
    "```\n",
    "\n",
    "Use Python to load this dataset into a DataFrame called `df`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 🔬 Test Case Checkpoint 🔬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## == CHECKPOINT TEST CASES ==\n",
    "# - This read-only cell contains test cases for your previous cell.\n",
    "# - If this cell runs without any errors, you PASSED all test cases!\n",
    "# - If this cell results in any errors, check your previous cell, make changes, and RE-RUN your code and then this cell.\n",
    "assert(len(df) == 69069), \"This is not the GPA dataset you're looking for.\"\n",
    "\n",
    "## == SUCCESS MESSAGE ==\n",
    "# You will only see this message (with the emoji showing) if you passed all test cases:\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "print(f\"{tada} All tests passed! {tada}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Puzzle 1.1: The \"Average GPA\" Column\n",
    "Each row in the GPA Dataset represents a **course section** at Illinois. For our exploratory data analysis, we are going to need an additional `Average GPA` column.\n",
    "\n",
    "To create this column, we need to compute the **weighted average GPA** for each course section by taking into account the **number of students** who received each letter grade.\n",
    "\n",
    "Add this new `Average GPA` column to our DataFrame `df` by finding the **products** of the **weight** associated with each **letter grade** and the number of said **letter grade** earned in each course section, **summing these products**, and then **dividing** by the **number of students** in the course section.\n",
    "\n",
    "Remember:\n",
    "- The **weight** of letter grades are as follows: $[A+ = 4.0, A = 4.0, A- = 3.67, \\ldots  D- = 0.67, F = 0]$. <br> You can find a full scale at: https://registrar.illinois.edu/courses-grades/explanation-of-grades/\n",
    "- The `Students` column of our DataFrame contains the number of students in a course section\n",
    "- You've done this in your Mastery Platform homework before, now you're doing it for real :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Average GPA'] = ...\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 🔬 Test Case Checkpoint 🔬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## == TEST CASES for Puzzle 1.1 ==\n",
    "# - This read-only cell contains test cases for your previous cell.\n",
    "# - If this cell runs without any error or output, you PASSED all test cases!\n",
    "# - If this cell results in any errors, check your previous cell, make changes, and RE-RUN your code and then this cell.\n",
    "import math\n",
    "assert( len(df) == 69069  ), \"You shouldn't be changing the length of `df` when computing Average GPA.\"\n",
    "assert( \"Average GPA\" in df.columns), \"Make sure your new column is named 'Average GPA'.\"\n",
    "assert( math.isclose(df['Average GPA'].mean(), 3.3701121347989282)), \"Your calculation of the Average GPA is incorrect.\"\n",
    "\n",
    "## == SUCCESS MESSAGE ==\n",
    "# You'll only see this message (With the emoji showing) if you passed all test cases:\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "print(f\"{tada} All tests passed! {tada}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Puzzle 1.2: The \"Hardest\" and \"Easiest\" Courses?\n",
    "One way to judge a course's difficulty is to consider its **Average GPA**. \n",
    "\n",
    "Using the `Average GPA` column and the two cells below, find:\n",
    "- The **50** courses with the **lowest** `Average GPA`, storing in the DataFrame `df_hard`\n",
    "- The **50** courses with the **highest** `Average GPA`, storing the DataFrame `df_easy` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hard = ...\n",
    "df_hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_easy = ...\n",
    "df_easy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "Now, using your two new DataFrames (`df_hard` and `df_easy`), find:\n",
    "- The **mean course number** of the 50 hardest courses by GPA, storing in the variable `hard_avg`\n",
    "- The **mean course number** of the 50 easiest courses by GPA, storing in the variable `easy_avg`\n",
    "\n",
    "The **course number** of a course is stored in the **'Number'** column of our DataFrames. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_avg = ...\n",
    "hard_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "easy_avg = ...\n",
    "easy_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 🔬 Test Case Checkpoint 🔬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## == TEST CASE for Puzzle 1.2 ==\n",
    "# - This read-only cell contains test cases for your previous cell.\n",
    "# - If this cell runs without any error or output, you PASSED all test cases!\n",
    "# - If this cell results in any errors, check your previous cell(s), make changes, and RE-RUN your code and then this cell.\n",
    "import math\n",
    "assert( len(df_hard) == len(df_easy) == 50 ), \"Your df_hard and df_easy should be picking the 50 courses with the lowest / highest average GPA respectively. Please double check that you are selecting 50 courses.\"\n",
    "assert( math.isclose(df_hard['Average GPA'].sum(), 80.30481775738464) ), \"Your df_hard is calculated incorrectly. Make sure you are finding the 50 courses with the lowest Average GPA.\"\n",
    "assert( math.isclose(df_easy['Average GPA'].sum(), 199.38547959954138) ), \"Your df_easy is calculated incorrectly. Make sure you are finding the 50 courses with the highest Average GPA.\"\n",
    "assert( math.isclose(hard_avg, 166.42) ), \"Your calculation for the average course Number of 'hard' courses is incorrect. Make sure you are finding the mean of course numbers of df_hard.\"\n",
    "assert( math.isclose(easy_avg, 372.74) ), \"Your calculation for the average course Number of 'easy' courses is incorrect. Make sure you are finding the mean of course numbers of df_easy.\"\n",
    "\n",
    "## == SUCCESS MESSAGE ==\n",
    "# You'll only see this message (With the emoji showing) if you passed all test cases:\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "print(f\"{tada} All tests passed! {tada}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Analysis: \"Hardest\" and \"Easiest\" Courses? \n",
    "\n",
    "**Q1: After solving Puzzle 1.2, your friend has the following claim:**\n",
    "\n",
    "> *\"We know that the undergraduate courses are coded from 001 to 499, where a larger number (in the hundreds place) usually implies more advanced material.  Based on our results in the previous puzzles, the data shows that the junior-level and senior-level courses are clearly not the hardest courses at UIUC.\"*\n",
    "\n",
    "**Comment on your friend's claim below. Do you think they are correct? Explain why or why not in at least three complete sentences.**"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "*(✏️ Edit this cell to replace this text with your answer. ✏️)*"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2: GPA By Subject\n",
    "We've explored some of the GPA Dataset as a whole, but what if we want to investigate **differences in GPA by subject**? "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Puzzle 2.1: Grouping by Subject\n",
    "To look into the different Average GPAs for each Subject, we need to **group** our DataFrame. \n",
    "\n",
    "In the following cell, create a new DataFrame, `df_subject`, which will contain this grouped GPA data. Using `df.groupby()`, **group** our original DataFrame (`df`) by `Subject` so each **letter grade column** contains the **total number of students** receiving the same grade in that `Subject`. \n",
    "\n",
    "**NUMERIC ONLY**: For the agg function in the lab, we want to aggregate only the numeric columns:\n",
    "- To do this, when you use `.agg(\"...\")`, include the option `numeric_only=True`.\n",
    "- For example, to aggregate by `sum`, you would use: `.agg(\"sum\", numeric_only=True)`.\n",
    "- Instead, to aggregate by `count`, you would use: `.agg(\"count\", numeric_only=True)`.\n",
    "\n",
    "**DO I USE `count` or `sum`?**:\n",
    "- Each row in `df` represents a **course section** of a `Subject` with the **number of students** receiving grades for that course.\n",
    "- Do you want to \"count\" the number or rows, or \"sum\" the number of students receiving each grade?\n",
    "- And, don't forget to `.reset_index()`. :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subject = ...\n",
    "df_subject"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 🔬 Test Case Checkpoint 🔬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## == TEST CASE for Puzzle 2.1 ==\n",
    "# - This read-only cell contains test cases for your previous cell.\n",
    "# - If this cell runs without any error or output, you PASSED all test cases!\n",
    "# - If this cell results in any errors, check your previous cell(s), make changes, and RE-RUN your code and then this cell.\n",
    "import math\n",
    "assert( 'df_subject' in vars() ), \"Make sure your DataFrame grouped by 'Subject' is named 'df_subject'.\" \n",
    "assert( len(df_subject) == 172 ), \"Make sure you are grouping by 'Subject'. There are 172 Subjects in our original `df`, so the length of `df_subject` should be 170.\"\n",
    "assert( math.isclose(df_subject.Students.mean(), 23723.837209302324) ), \"Double-check that you are aggregating your df_subject correctly.\"\n",
    "\n",
    "## == SUCCESS MESSAGE ==\n",
    "# You'll only see this message (With the emoji showing) if you passed all test cases:\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "print(f\"{tada} All tests passed! {tada}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Puzzle 2.2: Fixing our `Average GPA` Column\n",
    "Your intuition may tell you that some columns in `df_subject` look off. This is correct - given the way we've grouped the data to find **total student counts** by grade , the `Year` and `Average GPA` columns are incorrect. \n",
    "\n",
    "Let's fix this by redefining the `Average GPA` column in our `df_subject`.\n",
    "\n",
    "The `Average GPA` column should contain the **weighted average GPA** of each `Subject` by taking into account the **number of students** who received each letter grade in said `Subject`. \n",
    "\n",
    "Remember:\n",
    "- The **weight** of letter grades are as follows: $[A+ = 4.0, A = 4.0, A- = 3.67, \\ldots  D- = 0.67, F = 0]$. <br> You can find a full scale at: https://registrar.illinois.edu/courses-grades/explanation-of-grades/\n",
    "- The `Students` column of our DataFrame contains the number of students in a `Subject`\n",
    "- This Puzzle is **strikingly similar** to **Puzzle 1.1** in this lab - just make sure you use `df_subject` this time! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subject['Average GPA'] = ...\n",
    "df_subject"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 🔬 Test Case Checkpoint 🔬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## == TEST CASES for Puzzle 2.2 ==\n",
    "# - This read-only cell contains test cases for your previous cell.\n",
    "# - If this cell runs without any error or output, you PASSED all test cases!\n",
    "# - If this cell results in any errors, check your previous cell, make changes, and RE-RUN your code and then this cell.\n",
    "import math\n",
    "assert( len(df_subject) == 172 ), \"You shouldn't be changing the length of `df_subject` when recomputing Average GPA.\"\n",
    "assert( \"Average GPA\" in df_subject.columns), \"Make sure your column is still named 'Average GPA'.\"\n",
    "assert( math.isclose(df_subject['Average GPA'].mean(), 3.4643567698520825) ), \"Your calculation of the Average GPA by Subject is incorrect.\"\n",
    "\n",
    "## == SUCCESS MESSAGE ==\n",
    "# You'll only see this message (With the emoji showing) if you passed all test cases:\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "print(f\"{tada} All tests passed! {tada}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Puzzle 2.3: The \"Hardest\" and \"Easiest\" Subjects?\n",
    "One way we can judge a Subject's difficulty is to consider its **Average GPA**. \n",
    "\n",
    "Using your `df_subject`'s  `Average GPA` column and the two cells below, find:\n",
    "- The **10** Subjects with the **lowest** `Average GPA`, storing in the DataFrame `hard_subjects`\n",
    "- The **10** Subjects with the **highest** `Average GPA`, storing the DataFrame `easy_subjects` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_subjects = ...\n",
    "hard_subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "easy_subjects = ...\n",
    "easy_subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 🔬 Test Case Checkpoint 🔬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## == TEST CASES for Puzzle 2.3 ==\n",
    "# - This read-only cell contains test cases for your previous cell.\n",
    "# - If this cell runs without any error or output, you PASSED all test cases!\n",
    "# - If this cell results in any errors, check your previous cell, make changes, and RE-RUN your code and then this cell.\n",
    "import math\n",
    "assert( len(hard_subjects) == len(easy_subjects) == 10 ), \"Make sure you are selecting the ten hardest or easiest subjects by GPA. This means your hard_subjects and easy_subjects DataFrames should both have exactly ten rows.\"\n",
    "assert( math.isclose(hard_subjects['Average GPA'].sum(), 29.72180057281505) ), \"Your calculation for the hardest subjects by GPA is incorrect. Remember, here harder = lower Average GPA.\"\n",
    "assert( math.isclose(easy_subjects['Average GPA'].sum(), 38.47633638756495) ), \"Your calculation for the easiest subjects by GPA is incorrect. Remember, here easier = higher Average GPA.\"\n",
    "\n",
    "## == SUCCESS MESSAGE ==\n",
    "# You'll only see this message (With the emoji showing) if you passed all test cases:\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "print(f\"{tada} All tests passed! {tada}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Analysis: \"Hardest\" and \"Easiest\" Subjects? \n",
    "\n",
    "**Q2: Observe the `Subject` column of the `hard_subjects` and `easy_subjects` you've found in Puzzle 2.3 above. Do you think these are truly the \"Hardest\" and \"Easiest\" subjects at Illinois? Explain why or why not.** \n",
    "\n",
    "\n",
    "*Note: You can use http://catalog.illinois.edu/courses-of-instruction/ to find what the different `Subject` codes mean.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "*(✏️ Edit this cell to replace this text with your answer. ✏️)*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Puzzle 2.4: Visualizing GPA by Subject\n",
    "We've got the **Average GPA** of each `Subject` at Illinois, but what if we want to look at the **bigger picture** across all subjects? Well, data visualization comes to the rescue!\n",
    "\n",
    "Generate a **histogram** of the **Average GPA** in your `df_subject`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Analysis: Histogram Interpretations\n",
    "\n",
    "**Q3: Based on the histogram you generated above, what do you think the Average GPA across all courses in a typical Subject at Illinois is? No need for an exact answer, just estimate.** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "*(✏️ Edit this cell to replace this text with your answer. ✏️)*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Puzzle 2.5: Your Major! \n",
    "We've done a lot of analysis on every course and every subject, but Data Science should also be personal to you!\n",
    "\n",
    "Using your `df_subject`, isolate the row containing the `Subject` of **your Major**, storing in the variable `my_subject`:\n",
    "\n",
    "(If you're undecided, you can pick any `Subject`!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_subject = ...\n",
    "my_subject"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Analysis: Your Major's Average GPA\n",
    "\n",
    "**Q4: Observe the `Average GPA` column of your subject from Puzzle 2.5 above. Is it higher or lower than you expected?** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "*(✏️ Edit this cell to replace this text with your answer. ✏️)*"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3: GPA By Year\n",
    "At this point, we've investigated the GPA Dataset as a whole and grouped by `Subject`. While our GPA Dataset contains **a lot** of course data, some of the listed courses are quite old: **dating back to 2010**! To put that into perspective, a senior in college now would be no more than **10 years old** in 2010. \n",
    "\n",
    "One can question the changes to GPA **over time**. Some questions may include:\n",
    "- Has GPA gone up, because classes became \"easier\"? \n",
    "- Has the GPA fallen because of stricter grading policies? \n",
    "- How was GPA impacted in 2019-2020 at the brunt of COVID? \n",
    "\n",
    "You will gain some insight into the answers to questions in this section of the lab. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Puzzle 3.1: Grouping by Year\n",
    "To look into how the GPA changes by `Year`, we need to again **group** our DataFrame. \n",
    "\n",
    "In the following cell, create a new DataFrame, `df_year`, which will contain this grouped GPA data. Using `df.groupby()`, **group** our original DataFrame (`df`) by `Year` so each **letter grade column** contains the **total number of students** receiving said grade in that `Year`. \n",
    "\n",
    "Remember: You did something quite similar in Puzzle 2.1 to create `df_subject`. This might help you decide what type of **aggregation** (`.agg()`) to use when **grouping**. And, don't forget to `.reset_index()`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_year = ...\n",
    "df_year"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 🔬 Test Case Checkpoint 🔬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## == TEST CASE for Puzzle 3.1 ==\n",
    "# - This read-only cell contains test cases for your previous cell.\n",
    "# - If this cell runs without any errors, you PASSED all test cases!\n",
    "# - If this cell results in any errors, check your previous cell, make changes, and RE-RUN your code and then this cell.\n",
    "import math\n",
    "assert( 'df_year' in vars() ), \"Make sure your DataFrame grouped by Year is named 'df_year'.\" \n",
    "assert( len(df_year) == 14 ), \"Make sure you are grouping by 'Year'. There are 14 years in our original `df`, so the length of `df_years` should be 14.\"\n",
    "assert( math.isclose(df_year.Students.mean(), 291464.28571428574) ), \"Double-check that you are aggregating your df_year correctly.\"\n",
    "\n",
    "## == SUCCESS MESSAGE ==\n",
    "# You will only see this message (with the emoji showing) if you passed all test cases:\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "print(f\"{tada} All tests passed! {tada}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Puzzle 3.2: Fixing our `Average GPA` Column Again\n",
    "Some columns in `df_year` are incorrectly calculated given the way we've grouped the data.\n",
    "\n",
    "Let's fix this by redefining the `Average GPA` column in our `df_year`.\n",
    "\n",
    "The `Average GPA` column should contain the **weighted average GPA** of each `Year` by taking into account the **number of students** who received each letter grade in said `Year`. \n",
    "\n",
    "Remember: You've done this twice before in **Puzzle 1.1** and **Puzzle 2.1** - just make sure you use `df_year` this time! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 🔬 Test Case Checkpoint 🔬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## == TEST CASE for Puzzle 3.2 ==\n",
    "# - This read-only cell contains test cases for your previous cell.\n",
    "# - If this cell runs without any errors, you PASSED all test cases!\n",
    "# - If this cell results in any errors, check your previous cell, make changes, and RE-RUN your code and then this cell.\n",
    "import math\n",
    "assert( len(df_year) == 14 ), \"You shouldn't be changing the length of `df_year` when recomputing Average GPA.\"\n",
    "assert( \"Average GPA\" in df_year.columns), \"Make sure your column is still named 'Average GPA'.\"\n",
    "assert( math.isclose(df_year['Average GPA'].mean(), 3.3272744718333738) ), \"Your calculation of the Average GPA by Year is incorrect.\"\n",
    "\n",
    "## == SUCCESS MESSAGE ==\n",
    "# You will only see this message (with the emoji showing) if you passed all test cases:\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "print(f\"{tada} All tests passed! {tada}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Puzzle 3.3: Visualizing GPA over Time\n",
    "We now have the data of the `Average GPA` across the University over time in years. Using this data, we can generate yet another visualization built-in to Pandas to visualize this data: a **line plot**! \n",
    "\n",
    "You can plot a **connected line** that draws your **numeric data** from a DataFrame, `df`, using the syntax:\n",
    "\n",
    "&emsp;`df.plot.line(x='column1', y='column2')`\n",
    "\n",
    "This line of code plots the line and specifies the **column names** to be used for the **x-values** and **y-values** of the points on your line plot.\n",
    "\n",
    "\n",
    "In the cell below, using similar syntax, plot the **average GPA over time** using `df_year`. \n",
    "\n",
    "*Hint: the `Year` column should provide **x-values** and the `Average GPA` column should provide **y-values**.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "***Side Note***: If you're using **Visual Studio Code** on **dark mode**, you may not be able to see the **axes** and **axes labels** of the graph. \n",
    "\n",
    "**Only if** this is the case, please **copy and run** the following **two lines** of code in a cell:\n",
    "\n",
    "---\n",
    "```py\n",
    "from matplotlib import style\n",
    "style.use('dark_background')\n",
    "```\n",
    "---\n",
    "\n",
    "And then **re-run your plotting code** above. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Analysis: Plotted GPA over Time\n",
    "\n",
    "**Q5: Note a few observations you have about the changes to `Average GPA` at Illinois over time. Is there an overall trend? What events could have spiked increases to the Average GPA? Respond with at least three sentences.** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "*(✏️ Edit this cell to replace this text with your answer. ✏️)*"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission\n",
    "\n",
    "You're almost done!  All you need to do is to commit your lab to GitHub:\n",
    "\n",
    "1.  ⚠️ **Make certain to save your work.** ⚠️ To do this, go to **File => Save All**\n",
    "\n",
    "2.  After you have saved, exit this notebook and follow the Canvas instructions to commit this lab to your Git repository!\n",
    "\n",
    "3. Your TA will grade your submission and provide you feedback after the lab is due. :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "f48b0ea9e8281b29b1f9b6045fc5406bb9891af892053a27454c097f6ae51d2c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
